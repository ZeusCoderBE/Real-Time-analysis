{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hdang\\AppData\\Local\\Temp\\ipykernel_41316\\1299149357.py:74: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  error_message = soup_review.find(text=\"Xin lỗi, chúng tôi không tìm thấy trang mà bạn cần!\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "url = \"https://www.thegioididong.com/laptop\"\n",
    "driver.get(url)\n",
    "\n",
    "# Allow some time for the page to load\n",
    "time.sleep(3)\n",
    "\n",
    "# Get page source and parse it with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Extract all brand URLs (e.g., HP, Asus, Dell)\n",
    "brand_links = []\n",
    "brand_list = soup.find_all('a', class_='box-quicklink__item')\n",
    "\n",
    "for brand in brand_list:\n",
    "    href = brand.get('data-href')\n",
    "    if href:\n",
    "        brand_links.append(href)\n",
    "\n",
    "# Close the driver after extracting brand URLs\n",
    "driver.quit()\n",
    "\n",
    "# Initialize lists to store product details\n",
    "product_details = []\n",
    "\n",
    "# Loop through each brand page to extract product data\n",
    "for brand_url in brand_links:\n",
    "    # Initialize the Chrome driver\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    # Open the brand page\n",
    "    driver.get(brand_url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Click on \"Xem thêm\" if available\n",
    "    while True:\n",
    "        try:\n",
    "            see_more_button = driver.find_element_by_css_selector('div.view-more a')\n",
    "            see_more_button.click()\n",
    "            time.sleep(3)  # Allow time for the page to load more products\n",
    "        except:\n",
    "            break  # Exit loop if no more \"Xem thêm\" button is found\n",
    "    \n",
    "    # Get page source and parse it with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Extract all product links from the brand page\n",
    "    product_list = soup.find_all('a', class_='main-contain')\n",
    "    product_links = []\n",
    "    \n",
    "    for link in product_list:\n",
    "        href = link.get('href')\n",
    "        if href:\n",
    "            product_page_url = 'https://www.thegioididong.com' + href\n",
    "            review_page_url = product_page_url + \"/danh-gia\"  # Add \"/danh-gia\" to check for the review page\n",
    "            \n",
    "            # Initialize Chrome driver for review page check\n",
    "            driver = webdriver.Chrome()\n",
    "            driver.get(review_page_url)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # Get the review page content\n",
    "            soup_review = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Check if review page exists\n",
    "            error_message = soup_review.find(text=\"Xin lỗi, chúng tôi không tìm thấy trang mà bạn cần!\")\n",
    "            \n",
    "            # If the review page exists, add to product_links\n",
    "            if not error_message:\n",
    "                product_links.append(review_page_url)\n",
    "            \n",
    "            driver.quit()\n",
    "    \n",
    "    # Close the driver for the brand page\n",
    "    driver.quit()\n",
    "    \n",
    "    # Now, open each valid product review link to extract details\n",
    "    for link in product_links:\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(link)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Get page source and parse it with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Extract product name\n",
    "        product_name = 'N/A'\n",
    "        product_name_tag = soup.find('div', class_='content')\n",
    "\n",
    "        if product_name_tag:\n",
    "            # Try to find the product name in <h1>, <h2>, <h3>\n",
    "            h1_tag = product_name_tag.find('h1')\n",
    "            if h1_tag:\n",
    "                product_name = h1_tag.text.strip()\n",
    "            else:\n",
    "                h2_tag = product_name_tag.find('h2')\n",
    "                if h2_tag:\n",
    "                    product_name = h2_tag.text.strip()\n",
    "                else:\n",
    "                    h3_tag = product_name_tag.find('h3')\n",
    "                    if h3_tag:\n",
    "                        product_name = h3_tag.text.strip()\n",
    "        \n",
    "        # Extract current price only\n",
    "        price_current = 'N/A'\n",
    "        price_section = soup.find('div', class_='price')\n",
    "        if price_section:\n",
    "            price_current_tag = price_section.find('strong', class_='price-current')\n",
    "            if price_current_tag:\n",
    "                price_current = price_current_tag.text.strip()\n",
    "\n",
    "        # Extract reviews if available\n",
    "        reviews = soup.find_all('li', class_='par')\n",
    "        \n",
    "        for review in reviews:\n",
    "            name = review.find('p', class_='cmt-top-name').text.strip()\n",
    "            rating = len(review.find_all('i', class_='iconcmt-starbuy'))\n",
    "            comment = review.find('p', class_='cmt-txt').text.strip()\n",
    "            time_used_element = review.find('span', class_='cmtd dot-line')\n",
    "            time_used = time_used_element.text.strip() if time_used_element else 'N/A'\n",
    "\n",
    "            product_details.append({\n",
    "                'Product Name': product_name,\n",
    "                'Current Price': price_current,\n",
    "                'Reviewer': name,\n",
    "                'Rating': rating,\n",
    "                'Comment': comment,\n",
    "                'Time Used': time_used\n",
    "            })\n",
    "        \n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the collected data to a DataFrame\n",
    "df = pd.DataFrame(product_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('../data/laptop_data.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Data has been exported to 'laptop_reviews_by_brand.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM-xmUrTfoX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
